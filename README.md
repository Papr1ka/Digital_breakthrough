Решение доступно в интерактивном режиме по url http://ikbo.fun/.

# Альянс Раменки и Щёлково 
Представляем вам наше решение поставленной задачи, которая упростит работу сотрудников музеев
## Особенности нашего решения
Все наши модели используют одну и ту же базовую предобработку в виде модели ViT. Потенциально это может сэкономить много вычислительных мощностей и времени. 
Также использование трансформеров может гарантировать, что модель не будет бояться огромных датасетов, потенциально увеличение объема может даже повысить точность модели.
### Решение первой задачи
Алгоритм FAISS позволяет эффективно находить расстояние между многомерными векторами. Предварительно мы составляем базу данных, которая разбивается на кластеры на основании похожести фото(а точнее их векторных представлений).
При поступлении фотки от пользователя мы пропускаем её через ViT. На выходе мы получим её в виде вектора. Далее мы начинаем поиск похожих в базе данных. В результате экспериментирования мы пришли к выводу, что снижение размерности при помощи PCA матрицы выдает более качественные результаты, поэтому оставили это в финальном решении.

### Решение второй задачи 
В этой задачи мы отправляем выход ViT на многослойный перцептрон, размер финального слоя которого равен числу классов, представленных в датасете. 

### Решение третьей задачи 
Теперь мы отправляем выход ViT нейросеть-декодер, в данном случае мы выбрали GPT2, потому что выбранная нами версия обучена работе с русским языком, так что нам остается лишь дообучить на предоставленных описаниях. 
Посредством векторного представления фото, она обучается создавать им векторное представление слов. Из-за легкости GPT2 описания получились не слишком длинными, но модель научилась ёмко описывать на фото главное.

### Что можно было бы доработать 
Можно попробовать использовать metric learning в первой задаче, чтобы сильнее разграничить непохожие друг на друга фотки. 
Во второй задаче можно выбрать более сложную архитектуру и проверить, улучшится ли от этого точность итоговой модели.
В задаче описания можно попробовать имплементировать другие декодеры, например Сайгу или Вихрь. Но необходимо понимать, что с увеличением сложности модели возрастут и необходимые вычислительные мощности.


### Установка сайта

Для сайта работы сайта необходим тестовый датасет, а также веса, они поставляются отдельно.

Датасет за исключением папки train с изображениями доступен по ссылке https://drive.google.com/drive/folders/16niLSVHE2lRF_ZZSgUIpfhppk4Ma9_hc?usp=sharing

Архив необходимо скачать, разорхивировать и расширить, добавив туда папку с тренировочными изображениями.

Создан докер контейнер

Развёртывание:

Файл docker-compose.yml:

```
volumes:
    - <путь к папке train_dataset_mincult-train>:/usr/src/data
    - <путь к папке с весами>:/usr/src/weights
```

1. `git clone https://github.com/Papr1ka/Digital_breakthrough`
2. `cd Digital_breakthrough`
3. `docker build -t hackaton .`
4. `docker compose up`

В связи с некоторыми ограничениями по оперативной памяти, генерация описания была отключена, так как с ней процесс контейнера убивается OS.

[./ai](./ai) - Юпитер блокноты, используемые во время разработки.

[./web](./ai) - Веб сервер с инференсными моделями, используемыми во время разработки.

Связаться с командой:

https://t.me/retrowave_moya_zhizn - Капитан команды

https://t.me/TheLastPapr1ka

https://t.me/tmlef

https://t.me/chocoenjoyer

https://t.me/sokkop
